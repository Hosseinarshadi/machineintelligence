{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions as Real-valued Circuits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Case: Single Gate in the Circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Multiply Gate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we are going to compute is a simple function of two variables $F = f(X,Y)=X*Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/neural_networks_01.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The circuit takes two real-valued inputs $X$ and $Y$, computes the product $X*Y$ defined by the function $f$ and stores it in the variable $F$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(X,Y):\n",
    "    return X*Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output F is: -6\n"
     ]
    }
   ],
   "source": [
    "F = f(-2,3)\n",
    "print (f'The output F is: {F}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>*How should one tweak the inputs $(X,Y)$ slightly to increase the output of the function __f__?*</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy #1 - Numerical Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The partial derivative of the function $f$ with respect to $X$ can be computed as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\frac{\\partial f (X,Y)}{\\partial X} = \\lim_{h\\to 0} \\frac{f(X+h,Y)-f(X,Y)}{h} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be simulated in code by choosing $h$ to be a very small number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing a partial derivative with respect to $X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = -2; Y = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the derivative in respect to X is: 3.00000000000189\n"
     ]
    }
   ],
   "source": [
    "X_derivative = (f(X+h, Y)-f(X, Y))/h\n",
    "print (f'the derivative in respect to X is: {X_derivative}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive derivative value indicates that $X$ should be increased in order to increase $f$, let's try that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the original output is: -6\n",
      "the new output is: -5.4\n"
     ]
    }
   ],
   "source": [
    "print (f'the original output is: {f(-2,3)}')\n",
    "# increase X for a small value, for example 0.2\n",
    "print (f'the new output is: {f(-1.8,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$-5.4$ is larger than $-6$, it works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compute a partial derivative with respect to $Y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the derivative in respect to Y is: -2.0000000000042206\n"
     ]
    }
   ],
   "source": [
    "Y_derivative = (f(X, Y+h)-f(X, Y))/h\n",
    "print (f'the derivative in respect to Y is: {Y_derivative}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative derivative value indicates that $Y$ should be decreased in order to increase $f$, let's try that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the original output is: -6\n",
      "the new output is: -5.8\n"
     ]
    }
   ],
   "source": [
    "print (f'the original output is: {f(-2,3)}')\n",
    "# decrease Y for a small value, for example 0.1\n",
    "print (f'the new output is: {f(-2,2.9)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$-5.8$ is larger than $-6$, it works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __gradient__ of a function is made up of all the partial derivatives of this function concatenated in a vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\nabla f(X,Y)=\\left[\\frac{\\partial f (X,Y)}{\\partial X},\\frac{\\partial f (X,Y)}{\\partial Y}\\right]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradually minimizing a function by using derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to gradually maximize the function $f$ (step-by-step) towards our desired result, we need to update our parameters. This is done by adding to the parameter's value the value of its partial derivative. To achieve this gradually in small steps, we multiply the value of the partial derivative by a a small number (step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original output F is: -6\n"
     ]
    }
   ],
   "source": [
    "step_size = 0.01\n",
    "F = f(X,Y)\n",
    "print (f'The original output F is: {F}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is: -1.969999999999981, Y is: 2.979999999999958\n"
     ]
    }
   ],
   "source": [
    "X = X + step_size * X_derivative\n",
    "Y = Y + step_size * Y_derivative\n",
    "print (f'X is: {X}, Y is: {Y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old output: -6\n",
      "new output: -5.87059999999986\n"
     ]
    }
   ],
   "source": [
    "F_new = f(X,Y)\n",
    "print (f'old output: {F}\\nnew output: {F_new}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new output is larger than the old, thanks to partial derivatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach, however, is still expensive because we need to compute the circuitâ€™s output as we tweak every input value independently a small amount. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy #2 - Analytic Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use calculus to compute partial derivatives of the function $f(X,Y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\frac{\\partial F}{\\partial X}=\\frac{\\partial f (X,Y)}{\\partial X} = \\lim_{h\\to 0} \\frac{f(X+h,Y)-f(X,Y)}{h} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partial derivative of $F=f(X,Y)$ in respect to $X$ is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{\\partial F}{\\partial X}=\\frac{\\partial f (X,Y)}{\\partial X} &= \\lim_{h\\to 0} \\frac{f(X+h,Y)-f(X,Y)}{h} \\\\\\\\\n",
    "&=\\lim_{h\\to 0}\\frac{(X+h)Y -XY}{h} \\\\\n",
    "&=\\lim_{h\\to 0}\\frac{XY+Yh-XY}{h} \\\\\n",
    "&=\\lim_{h\\to 0}\\frac{Yh}{h} \\\\\n",
    "\\frac{\\partial F}{\\partial X}=\\frac{\\partial f (X,Y)}{\\partial X}&=Y\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partial derivative of $F=f(X,Y)$ in respect to $Y$ is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{\\partial F}{\\partial Y}=\\frac{\\partial f (X,Y)}{\\partial Y} &= \\lim_{h\\to 0} \\frac{f(X,Y+h)-f(X,Y)}{h} \\\\\\\\\n",
    "&=\\lim_{h\\to 0}\\frac{X(Y+h) -XY}{h} \\\\\n",
    "&=\\lim_{h\\to 0}\\frac{XY+Xh-XY}{h} \\\\\n",
    "&=\\lim_{h\\to 0}\\frac{Xh}{h} \\\\\n",
    "\\frac{\\partial F}{\\partial Y}=\\frac{\\partial f (X,Y)}{\\partial Y} &=X\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are both partial derivatives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{\\partial F}{\\partial X}=Y ; \\frac{\\partial F}{\\partial Y}=X \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can represent this as a gradient:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\nabla f(X,Y)=\\left[Y,X\\right]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this information to increase the output of the function __f__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the output F is: -6\n"
     ]
    }
   ],
   "source": [
    "X = -2; Y = 3\n",
    "F = f(X,Y)\n",
    "print (f'the output F is: {F}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/neural_networks_02.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-gradient: 3 \n",
      "Y-gradient: -2\n"
     ]
    }
   ],
   "source": [
    "X_gradient = Y\n",
    "Y_gradient = X\n",
    "print (f'X-gradient: {X_gradient} \\nY-gradient: {Y_gradient}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/neural_networks_03.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is now: -1.997, \n",
      "Y is now: 2.998\n"
     ]
    }
   ],
   "source": [
    "step_size = 0.001\n",
    "X = X + step_size * X_gradient\n",
    "Y = Y + step_size * Y_gradient\n",
    "print (f'X is now: {X}, \\nY is now: {Y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old output: -6\n",
      "new output: -5.987006000000001\n"
     ]
    }
   ],
   "source": [
    "F_new = f(X,Y)\n",
    "print (f'old output: {F}\\nnew output: {F_new}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new output $-5.8706$ is larger than the old: $-6$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Add Gate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second function we're going to compute is  $G=g(X,Y)=X+Y.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/neural_networks_04.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The circuit takes two real-valued inputs $X$ and $Y$ and computes the sum $X+Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(X,Y):\n",
    "    return X+Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output is: 1\n"
     ]
    }
   ],
   "source": [
    "X = -2; Y = 3\n",
    "G = g(X,Y)\n",
    "print (f'The output is: {G}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/neural_networks_05.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did before, we can use calculus to compute partial derivatives for the function $G=g(X,Y)$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\frac{\\partial G}{\\partial X}=\\frac{\\partial g (X,Y)}{\\partial X} = \\lim_{h\\to 0} \\frac{g(X+h,Y)-g(X,Y)}{h} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partial derivative of $G=g(X,Y)$ in respect to $X$ is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{\\partial G}{\\partial X}=\\frac{\\partial g (X,Y)}{\\partial X} &= \\lim_{h\\to 0} \\frac{g(X+h,Y)-g(X,Y)}{h} \\\\\\\\\n",
    "&=\\lim_{h\\to 0}\\frac{X+h+Y -X-Y}{h} \\\\\n",
    "\\frac{\\partial G}{\\partial X}=\\frac{\\partial g (X,Y)}{\\partial X}&=\\lim_{h\\to 0}\\frac{h}{h} =1 \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partial derivative of $G=g(X,Y)$ in respect to $Y$ is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{\\partial G}{\\partial Y}=\\frac{\\partial g (X,Y)}{\\partial Y} &= \\lim_{h\\to 0} \\frac{g(X,Y+h)-g(X,Y)}{h} \\\\\\\\\n",
    "&=\\lim_{h\\to 0}\\frac{X+Y+h -X-Y}{h} \\\\\n",
    "\\frac{\\partial G}{\\partial Y}=\\frac{\\partial g (X,Y)}{\\partial Y}&=\\lim_{h\\to 0}\\frac{h}{h} =1 \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both partial derivatives $\\frac{\\partial G}{\\partial X}$ and $\\frac{\\partial G}{\\partial Y}$ in this case are equal to $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this information to maximize the function __g__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-gradient: 1 \n",
      "Y-gradient: 1\n"
     ]
    }
   ],
   "source": [
    "X_gradient = 1\n",
    "Y_gradient = 1\n",
    "print (f'X-gradient: {X_gradient} \\nY-gradient: {Y_gradient}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/neural_networks_06.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is: -1.99 \n",
      "Y is: 3.01\n"
     ]
    }
   ],
   "source": [
    "step_size = 0.01\n",
    "X = X + step_size * X_gradient\n",
    "Y = Y + step_size * Y_gradient\n",
    "print (f'X is: {X} \\nY is: {Y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old output: -6\n",
      "new output: 1.0199999999999998\n"
     ]
    }
   ],
   "source": [
    "F_new = g(X,Y)\n",
    "print (f'old output: {F}\\nnew output: {F_new}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Recursive Case: Circuits with Multiple Gates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expression we are computing now is $M = m(X,Y,Z)=(X+Y)*Z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/neural_networks_07.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m(X,Y,Z):\n",
    "    return (X+Y)*Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = -2; Y = 5; Z = -4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is equal to $M=m(-2,5,-4)=(-2+5)-4=3*-4=-12$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the output M is: -12\n"
     ]
    }
   ],
   "source": [
    "M = m(X,Y,Z)\n",
    "print (f'the output M is: {M}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/neural_networks_08.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did before, we can use calculus to derive partial derivatives for the function $M=m(X,Y,Z)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\frac{\\partial M}{\\partial X}=\\frac{\\partial m (X,Y,Z)}{\\partial X} = \\lim_{h\\to 0} \\frac{m(X+h,Y,Z)-m(X,Y,Z)}{h} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partial derivative of $M=m(X,Y,Z)$ in respect to $X$ is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{\\partial M}{\\partial X}=\\frac{\\partial m(X,Y,Z)}{\\partial X} &= \\lim_{h\\to 0} \\frac{f(X+h,Y,Z)-f(X,Y,Z)}{h} \\\\\\\\\n",
    "&=\\lim_{h\\to 0}\\frac{(X+h+Y)*Z -(X+Y)*Z}{h} \\\\\n",
    "&=\\lim_{h\\to 0}\\frac{ZX+Zh+ZY-ZX-ZY}{h} \\\\\n",
    "\\frac{\\partial M}{\\partial X}=\\frac{\\partial m(X,Y,Z)}{\\partial X}&=\\lim_{h\\to 0}\\frac{Zh}{h} =Z \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, partial derivative of $M=m(X,Y,Z)$ in respect to $Y$ is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{\\partial M}{\\partial Y}=\\frac{\\partial m(X,Y,Z)}{\\partial Y} &= \\lim_{h\\to 0} \\frac{f(X,Y+h,Z)-f(X,Y,Z)}{h} \\\\\\\\\n",
    "&=\\lim_{h\\to 0}\\frac{(X+Y+h)*Z -(X+Y)*Z}{h} \\\\\n",
    "&=\\lim_{h\\to 0}\\frac{ZX+ZY+Zh-ZX-ZY}{h} \\\\\n",
    "\\frac{\\partial M}{\\partial Y}=\\frac{\\partial m(X,Y,Z)}{\\partial Y}&=\\lim_{h\\to 0}\\frac{Zh}{h} =Z \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partial derivative of $M=m(X,Y,Z)$ in respect to $Z$ is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{\\partial M}{\\partial Z}=\\frac{\\partial m(X,Y,Z)}{\\partial Z} &= \\lim_{h\\to 0} \\frac{f(X,Y,Z+h)-f(X,Y,Z)}{h} \\\\\\\\\n",
    "&=\\lim_{h\\to 0}\\frac{(X+Y)*(Z+h) -(X+Y)*Z}{h} \\\\\n",
    "&=\\lim_{h\\to 0}\\frac{XZ+Xh+YZ+Yh-XZ-YZ}{h} \\\\\n",
    "&=\\lim_{h\\to 0}\\frac{Xh+Yh}{h} \\\\\n",
    "&=\\lim_{h\\to 0}\\frac{h(X+Y)}{h}\\\\\n",
    "\\frac{\\partial M}{\\partial Z}=\\frac{\\partial m(X,Y,Z)}{\\partial Z}&=X+Y \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are all three partial derivatives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{\\partial M}{\\partial X}=Z ; \\frac{\\partial M}{\\partial Y}=Z ;\\frac{\\partial M}{\\partial Z}=X+Y \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can represent this as a gradient:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\nabla m(X,Y,Z)=\\left[Z,Z,X+Y\\right]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this information to maximize the output of the function __m__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-gradient: -4 \n",
      "Y-gradient: -4 \n",
      "Z-gradient: 3\n"
     ]
    }
   ],
   "source": [
    "X_gradient = Z\n",
    "Y_gradient = Z\n",
    "Z_gradient = X+Y\n",
    "print (f'X-gradient: {X_gradient} \\nY-gradient: {Y_gradient} \\nZ-gradient: {Z_gradient}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/neural_networks_09.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is: -2.04 \n",
      "Y is: 4.96 \n",
      "Z is: -3.97\n"
     ]
    }
   ],
   "source": [
    "step_size = 0.01\n",
    "X = X + step_size * X_gradient\n",
    "Y = Y + step_size * Y_gradient\n",
    "Z = Z + step_size * Z_gradient\n",
    "print (f'X is: {X} \\nY is: {Y} \\nZ is: {Z}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old output: -12\n",
      "new output: -11.5924\n"
     ]
    }
   ],
   "source": [
    "M_new = m(X,Y,Z)\n",
    "print (f'old output: {M}\\nnew output: {M_new}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of working with the function $m(X,Y,Z)=(X+Y)*Z$, we can simplify the computation by composing two new simpler functions: <br>$G=g(X,Y)=X+Y$, and <br>$F=f(G,Z)=G*Z$, into: <br>$F=f(g(X,Y),Z)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/neural_networks_10.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can apply the chain rule for derivation, because $F$ is a function of $G$ and $G$ is a function of $X$ and $Y$.<br>\n",
    "So instead of computing $\\frac{\\partial M}{\\partial X}$, $\\frac{\\partial M}{\\partial Y}$  and $\\frac{\\partial M}{\\partial Z}$ which gets more complicated to compute with more complex expressions, we compute instead $\\frac{\\partial F}{\\partial X}$, $\\frac{\\partial F}{\\partial Y}$ and $\\frac{\\partial F}{\\partial Z}$, which can be decomposed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{\\partial F}{\\partial X}=\\frac{\\partial F}{\\partial G}\\frac{\\partial G}{\\partial X}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here $\\frac{\\partial F}{\\partial G}$ is a simple multiplication gate, whose derivate we have already computed:$\\frac{\\partial F}{\\partial G}$ =$\\frac{\\partial f(G,Z)}{\\partial G}=Z$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also $\\frac{\\partial G}{\\partial X}$ is a simple addition gate, whose derivate we have already computed: $\\frac{\\partial G}{\\partial X}$ =$\\frac{\\partial g(X,Y)}{\\partial X}=1$, thus:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{\\partial F}{\\partial X}=\\frac{\\partial F}{\\partial G}\\frac{\\partial G}{\\partial X} = Z*1 = Z\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same applies when computing the partial $\\frac{\\partial F}{\\partial Y}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{\\partial F}{\\partial Y}=\\frac{\\partial F}{\\partial G}\\frac{\\partial G}{\\partial Y}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{\\partial F}{\\partial Y}=\\frac{\\partial F}{\\partial G}\\frac{\\partial G}{\\partial Y} = Z*1 = Z\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The partial derivative $\\frac{\\partial F}{\\partial Z}$ does not need to be decomposed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{\\partial F}{\\partial Z}=G=X+Y\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this information to maximize the output of the function __m_decomposed__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_decomposed(X,Y,Z):\n",
    "    G = g(X,Y)\n",
    "    F = f(G,Z)\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = -2; Y = 5; Z = -4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the output is: -12\n"
     ]
    }
   ],
   "source": [
    "F = m_decomposed(X,Y,Z)\n",
    "print (f'the output is: {F}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/neural_networks_11.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-gradient: -4, \n",
      "Y-gradient: -4, \n",
      "Z-gradient: 3.\n"
     ]
    }
   ],
   "source": [
    "X_gradient = Z\n",
    "Y_gradient = Z\n",
    "Z_gradient = X+Y\n",
    "print (f'X-gradient: {X_gradient}, \\nY-gradient: {Y_gradient}, \\nZ-gradient: {Z_gradient}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/neural_networks_12.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can observe, that in the backward pass, the multiplication gate switches the values of outputs: what used to be (3,-4) in the forward pass, it becomes (-4,3) in the backward pass. The addition gate, on the other hand just passes its input value to the ouput without changing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is: -2.04\n",
      "Y is: 4.96\n",
      "Z is: -3.97\n"
     ]
    }
   ],
   "source": [
    "step_size = 0.01\n",
    "X = X + step_size * X_gradient\n",
    "Y = Y + step_size * Y_gradient\n",
    "Z = Z + step_size * Z_gradient\n",
    "print (f'X is: {X}\\nY is: {Y}\\nZ is: {Z}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old output: -12\n",
      "new output: -11.5924\n"
     ]
    }
   ],
   "source": [
    "F_new = m(X,Y,Z)\n",
    "print (f'old output: {F}\\nnew output: {F_new}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: More complex functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a seemingly complicated function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "l(A,B,C,X,Y)&= \\frac{1}{1+e^{-(AX+BY+C)}}\\\\\n",
    "&or \\\\\n",
    "l(A,B,C,X,Y)&= \\sigma (AX+BY+C)\\\\\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\sigma$ is called a *sigmoid function*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\sigma&= \\frac{1}{1+e^{-x}}\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and it was used a lot in machine learning before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivative of the sigmoid function is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\frac{d\\sigma(x)}{dx}= \\sigma(x) * (1-\\sigma(x))\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which means that once we compute the final activation $F=\\sigma(AX+BY+C)$, we can simply calculate the derivative as $F*(1-F)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the forward pass of this function without a problem, however, directly computing the partial derivatives $\\frac{\\partial L}{\\partial A}$, $\\frac{\\partial L}{\\partial B}$, $\\frac{\\partial L}{\\partial C}$, ... could be tricky. It is much better to use the chain rule and compose multiple functions togeher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create 4 simple functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "G=g(A,X)&=A*X \\\\\n",
    "H=h(B,Y)&=B*Y \\\\\n",
    "K=k(G,H,C)&=G+H+C \\\\\n",
    "F=f(K)&= \\frac{1}{1+e^{-x}}\\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and compose them as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "F=f(k(g(A,X),h(B,Y),C))\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks much simpler on a diagram:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/neural_networks_13.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute all the partial derivatives by using the chain rule:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{\\partial F}{\\partial A}&=\\frac{\\partial F}{\\partial K}*\\frac{\\partial K}{\\partial G}*\\frac{\\partial G}{\\partial A} \\\\\n",
    "\\frac{\\partial F}{\\partial A}&= F(1-F)*1*X \\\\\n",
    "\\frac{\\partial F}{\\partial A}&= XF(1-F)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{\\partial F}{\\partial X}&=\\frac{\\partial F}{\\partial K}*\\frac{\\partial K}{\\partial G}*\\frac{\\partial G}{\\partial X} \\\\\n",
    "\\frac{\\partial F}{\\partial X}&= F(1-F)*1*A \\\\\n",
    "\\frac{\\partial F}{\\partial X}&= AF(1-F)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By following the exact same procedure for $B$, $Y$, and $C$ we get:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{\\partial F}{\\partial B}&=YF(1-F)\\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{\\partial F}{\\partial Y}&=BF(1-F)\\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{\\partial F}{\\partial C}&=F(1-F)\\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can represent this as a gradient:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\nabla l(A,B,C,X,Y)=\\left[XF(1-F),YF(1-F),F(1-F),AF(1-F),BF(1-F) \\right]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this information to maximize the output of the function __l__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l(A,B,C,X,Y):\n",
    "    G = f(A,X)\n",
    "    H = f(B,Y)\n",
    "    K = G + H + C\n",
    "    F = sigmoid(K)\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 1.0; B = 2.0; C = -3.0; X = -1.0; Y = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the output F is: 0.8807970779778823\n"
     ]
    }
   ],
   "source": [
    "F = l(A,B,C,X,Y)\n",
    "print (f'the output F is: {F}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/neural_networks_14.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since every partial derivative involves $F(1-F)$, we will compute it first as `F_K`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_K = 0.10499358540350662\n"
     ]
    }
   ],
   "source": [
    "gradient_end = 1\n",
    "F_K = (F * (1 - F)) * gradient_end\n",
    "print (f'F_K = {F_K}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A-gradient: -0.10499358540350662 \n",
      "X-gradient: 0.10499358540350662 \n",
      "B-gradient: 0.31498075621051985 \n",
      "Y-gradient: 0.20998717080701323\n",
      "C-gradient: 0.10499358540350662\n"
     ]
    }
   ],
   "source": [
    "A_gradient = X*F_K\n",
    "B_gradient = Y*F_K\n",
    "C_gradient = F_K\n",
    "X_gradient = A*F_K\n",
    "Y_gradient = B*F_K\n",
    "\n",
    "print (f'A-gradient: {A_gradient} \\nX-gradient: {X_gradient} \\nB-gradient: {B_gradient} \\nY-gradient: {Y_gradient}\\nC-gradient: {C_gradient}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/neural_networks_15.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A is: 0.998950064145965, \n",
      "B is: 2.0031498075621053, \n",
      "C is: -2.9989500641459648, \n",
      "X is: -0.998950064145965, \n",
      "Y is: 3.00209987170807\n"
     ]
    }
   ],
   "source": [
    "step_size = 0.01\n",
    "A = A + step_size * A_gradient\n",
    "B = B + step_size * B_gradient\n",
    "C = C + step_size * C_gradient\n",
    "X = X + step_size * X_gradient\n",
    "Y = Y + step_size * Y_gradient\n",
    "print (f'A is: {A}, \\nB is: {B}, \\nC is: {C}, \\nX is: {X}, \\nY is: {Y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old output: 0.8807970779778823\n",
      "new output: 0.8825501816218984\n"
     ]
    }
   ],
   "source": [
    "F_new = l(A,B,C,X,Y)\n",
    "print (f'old output: {F}\\nnew output: {F_new}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new output is higher than the old one!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
